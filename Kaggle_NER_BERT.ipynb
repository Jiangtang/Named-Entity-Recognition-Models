{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pursuant-panic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T02:08:05.872479Z",
     "start_time": "2021-05-07T02:08:05.869470Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specified-helena",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T02:08:05.918288Z",
     "start_time": "2021-05-07T02:08:05.873473Z"
    }
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    MAX_LEN = 128\n",
    "    TRAIN_BATCH_SIZE = 32\n",
    "    VALID_BATCH_SIZE = 8\n",
    "    EPOCHS = 3\n",
    "    BASE_MODEL_PATH = \"model/bert-base-uncased/\"\n",
    "    MODEL_PATH = \"model.bin\"\n",
    "    TRAINING_FILE = \"kg_ner/ner_dataset.csv\"\n",
    "    TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
    "        BASE_MODEL_PATH,\n",
    "        do_lower_case=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exciting-memorabilia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T02:08:05.933267Z",
     "start_time": "2021-05-07T02:08:05.920260Z"
    }
   },
   "outputs": [],
   "source": [
    "class EntityDataset:\n",
    "    def __init__(self, texts, pos, tags):\n",
    "        self.texts = texts\n",
    "        self.pos = pos\n",
    "        self.tags = tags\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        pos = self.pos[item]\n",
    "        tags = self.tags[item]\n",
    "\n",
    "        ids = []\n",
    "        target_pos = []\n",
    "        target_tag =[]\n",
    "\n",
    "        for i, s in enumerate(text):\n",
    "            inputs = config.TOKENIZER.encode(\n",
    "                s,\n",
    "                add_special_tokens=False\n",
    "            )\n",
    "            # abhishek: ab ##hi ##sh ##ek\n",
    "            input_len = len(inputs)\n",
    "            ids.extend(inputs)\n",
    "            target_pos.extend([pos[i]] * input_len)\n",
    "            target_tag.extend([tags[i]] * input_len)\n",
    "\n",
    "        ids = ids[:config.MAX_LEN - 2]\n",
    "        target_pos = target_pos[:config.MAX_LEN - 2]\n",
    "        target_tag = target_tag[:config.MAX_LEN - 2]\n",
    "\n",
    "        ids = [101] + ids + [102]\n",
    "        target_pos = [0] + target_pos + [0]\n",
    "        target_tag = [0] + target_tag + [0]\n",
    "\n",
    "        mask = [1] * len(ids)\n",
    "        token_type_ids = [0] * len(ids)\n",
    "\n",
    "        padding_len = config.MAX_LEN - len(ids)\n",
    "\n",
    "        ids = ids + ([0] * padding_len)\n",
    "        mask = mask + ([0] * padding_len)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
    "        target_pos = target_pos + ([0] * padding_len)\n",
    "        target_tag = target_tag + ([0] * padding_len)\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"target_pos\": torch.tensor(target_pos, dtype=torch.long),\n",
    "            \"target_tag\": torch.tensor(target_tag, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "personalized-headset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T02:08:05.948252Z",
     "start_time": "2021-05-07T02:08:05.934272Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    for data in tqdm(data_loader, total=len(data_loader)):\n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, _, loss = model(**data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        final_loss += loss.item()\n",
    "    return final_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    for data in tqdm(data_loader, total=len(data_loader)):\n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device)\n",
    "        _, _, loss = model(**data)\n",
    "        final_loss += loss.item()\n",
    "    return final_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "democratic-fifth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T02:08:05.963298Z",
     "start_time": "2021-05-07T02:08:05.949270Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(output, target, mask, num_labels):\n",
    "    lfn = nn.CrossEntropyLoss()\n",
    "    active_loss = mask.view(-1) == 1\n",
    "    active_logits = output.view(-1, num_labels)\n",
    "    active_labels = torch.where(\n",
    "        active_loss,\n",
    "        target.view(-1),\n",
    "        torch.tensor(lfn.ignore_index).type_as(target)\n",
    "    )\n",
    "    loss = lfn(active_logits, active_labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "class EntityModel(nn.Module):\n",
    "    def __init__(self, num_tag, num_pos):\n",
    "        super(EntityModel, self).__init__()\n",
    "        self.num_tag = num_tag\n",
    "        self.num_pos = num_pos\n",
    "        self.bert = transformers.BertModel.from_pretrained(\n",
    "            config.BASE_MODEL_PATH\n",
    "        )\n",
    "        self.bert_drop_1 = nn.Dropout(0.3)\n",
    "        self.bert_drop_2 = nn.Dropout(0.3)\n",
    "        self.out_tag = nn.Linear(768, self.num_tag)\n",
    "        self.out_pos = nn.Linear(768, self.num_pos)\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        ids, \n",
    "        mask, \n",
    "        token_type_ids, \n",
    "        target_pos, \n",
    "        target_tag\n",
    "    ):\n",
    "        o1, _ = self.bert(\n",
    "            ids, \n",
    "            attention_mask=mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        bo_tag = self.bert_drop_1(o1)\n",
    "        bo_pos = self.bert_drop_2(o1)\n",
    "\n",
    "        tag = self.out_tag(bo_tag)\n",
    "        pos = self.out_pos(bo_pos)\n",
    "\n",
    "        loss_tag = loss_fn(tag, target_tag, mask, self.num_tag)\n",
    "        loss_pos = loss_fn(pos, target_pos, mask, self.num_pos)\n",
    "\n",
    "        loss = (loss_tag + loss_pos) / 2\n",
    "\n",
    "        return tag, pos, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "together-anchor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T02:08:05.978290Z",
     "start_time": "2021-05-07T02:08:05.964270Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(data_path):\n",
    "    df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "\n",
    "    enc_pos = preprocessing.LabelEncoder()\n",
    "    enc_tag = preprocessing.LabelEncoder()\n",
    "\n",
    "    df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\n",
    "    df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n",
    "\n",
    "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "    pos = df.groupby(\"Sentence #\")[\"POS\"].apply(list).values\n",
    "    tag = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values\n",
    "    return sentences, pos, tag, enc_pos, enc_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "interpreted-moses",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T02:08:12.892610Z",
     "start_time": "2021-05-07T02:08:05.979286Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2b700dac0e43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEntityModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_tag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mparam_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 671\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "sentences, pos, tag, enc_pos, enc_tag = process_data(config.TRAINING_FILE)\n",
    "\n",
    "meta_data = {\n",
    "    \"enc_pos\": enc_pos,\n",
    "    \"enc_tag\": enc_tag\n",
    "}\n",
    "\n",
    "joblib.dump(meta_data, \"meta.bin\")\n",
    "\n",
    "num_pos = len(list(enc_pos.classes_))\n",
    "num_tag = len(list(enc_tag.classes_))\n",
    "\n",
    "(\n",
    "    train_sentences,\n",
    "    test_sentences,\n",
    "    train_pos,\n",
    "    test_pos,\n",
    "    train_tag,\n",
    "    test_tag\n",
    ") = model_selection.train_test_split(\n",
    "    sentences, \n",
    "    pos, \n",
    "    tag, \n",
    "    random_state=42, \n",
    "    test_size=0.1\n",
    ")\n",
    "\n",
    "train_dataset = EntityDataset(\n",
    "    texts=train_sentences, pos=train_pos, tags=train_tag\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4\n",
    ")\n",
    "\n",
    "valid_dataset = EntityDataset(\n",
    "    texts=test_sentences, pos=test_pos, tags=test_tag\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = EntityModel(num_tag=num_tag, num_pos=num_pos)\n",
    "model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(\n",
    "                nd in n for nd in no_decay\n",
    "            )\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(\n",
    "                nd in n for nd in no_decay\n",
    "            )\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "num_train_steps = int(\n",
    "    len(train_sentences) / config.TRAIN_BATCH_SIZE * config.EPOCHS\n",
    ")\n",
    "optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_train_steps\n",
    ")\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train_loss = train_fn(\n",
    "        train_data_loader, \n",
    "        model, \n",
    "        optimizer, \n",
    "        device, \n",
    "        scheduler\n",
    "    )\n",
    "    test_loss = eval_fn(\n",
    "        valid_data_loader,\n",
    "        model,\n",
    "        device\n",
    "    )\n",
    "    print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = joblib.load(\"meta.bin\")\n",
    "enc_pos = meta_data[\"enc_pos\"]\n",
    "enc_tag = meta_data[\"enc_tag\"]\n",
    "\n",
    "num_pos = len(list(enc_pos.classes_))\n",
    "num_tag = len(list(enc_tag.classes_))\n",
    "\n",
    "sentence = \"\"\"\n",
    "abhishek is going to india\n",
    "\"\"\"\n",
    "tokenized_sentence = config.TOKENIZER.encode(sentence)\n",
    "\n",
    "sentence = sentence.split()\n",
    "print(sentence)\n",
    "print(tokenized_sentence)\n",
    "\n",
    "test_dataset = EntityDataset(\n",
    "    texts=[sentence], \n",
    "    pos=[[0] * len(sentence)], \n",
    "    tags=[[0] * len(sentence)]\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = EntityModel(num_tag=num_tag, num_pos=num_pos)\n",
    "model.load_state_dict(torch.load(config.MODEL_PATH))\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = test_dataset[0]\n",
    "    for k, v in data.items():\n",
    "        data[k] = v.to(device).unsqueeze(0)\n",
    "    tag, pos, _ = model(**data)\n",
    "\n",
    "    print(\n",
    "        enc_tag.inverse_transform(\n",
    "            tag.argmax(2).cpu().numpy().reshape(-1)\n",
    "        )[:len(tokenized_sentence)]\n",
    "    )\n",
    "    print(\n",
    "        enc_pos.inverse_transform(\n",
    "            pos.argmax(2).cpu().numpy().reshape(-1)\n",
    "        )[:len(tokenized_sentence)]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
